{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMta+VW/lGa8k/G+V+oS8CJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamCholin/CS6910_Assignment_1/blob/main/SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WMlSMJmqlm-"
      },
      "source": [
        "import random          \r\n",
        "import numpy as np      \r\n",
        "from time import time    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcofG8yhqqYQ"
      },
      "source": [
        "def sigmoid(z):\r\n",
        "    return 1.0 / (1.0 + np.exp(-z))\r\n",
        "def dsigmoid(z):\r\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_X3V9XArT_m"
      },
      "source": [
        "def relu(z):\r\n",
        "    return np.maximum(z, 0)\r\n",
        "def drelu(z):\r\n",
        "    return np.heaviside(z, 1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYPGfYXsv_I-"
      },
      "source": [
        "def tanh(z):\r\n",
        "    return (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\r\n",
        "def dtanh(z):\r\n",
        "    return 1-tanh(z)**2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBnrQr7ArnSZ"
      },
      "source": [
        "def sgdlearn(nn, tr_data, epochs, batch_size, learning_rate):\r\n",
        "    n = len(tr_data)\r\n",
        "    for j in range(epochs):\r\n",
        "        time_start=time()\r\n",
        "        random.shuffle(tr_data)\r\n",
        "        batches = [tr_data[k: k + batch_size] for k in range(0,n,batch_size)]\r\n",
        "        for batch in batches:\r\n",
        "            sgd(nn, batch, learning_rate)\r\n",
        "        time_end=time()\r\n",
        "        print('Epoch {0}:time taken {1} seconds, accuracy {2}%'.format(f'{j + 1:2}',1.0*time_end-time_start, 100.0 * evaluate2(nn, tr_data) / len(tr_data)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMpeRG-YzmXL"
      },
      "source": [
        "def sgd(nn, batch, eta):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "    nn.weights = [w - (eta ) * nw for w, nw in zip(nn.weights, nw)]\r\n",
        "    nn.biases  = [b - (eta ) * nb for b, nb in zip(nn.biases, nb)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegcauxLqvIm"
      },
      "source": [
        "def dcost(act, y):\r\n",
        "    return (act - y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO4oZbwlqyzm"
      },
      "source": [
        "class Network:\r\n",
        "    num_layers=0\r\n",
        "    biases=[]\r\n",
        "    weights=[]\r\n",
        "    def __init__(self,nl,x,y,act1,act2):\r\n",
        "      self.num_layers=nl\r\n",
        "      self.biases=x\r\n",
        "      self.weights=y\r\n",
        "      self.act=act1\r\n",
        "      self.dact=act2\r\n",
        "\r\n",
        "def init_network(layers,actfunc):\r\n",
        "    if actfunc==\"tanh\":\r\n",
        "      act1=tanh\r\n",
        "      act2=dtanh\r\n",
        "    elif actfunc==\"sigmoid\":\r\n",
        "      act1=sigmoid\r\n",
        "      act2=dsigmoid\r\n",
        "    else:\r\n",
        "      act1=relu\r\n",
        "      act2=drelu\r\n",
        "    return Network(len(layers),[np.random.randn(y, 1) for y in layers[1:]],[np.random.randn(y, x) for x, y in zip(layers[:-1], layers[1:])],act1,act2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hHbAvP5rdA9"
      },
      "source": [
        "def forward(nn, a):\r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        a = nn.act(np.dot(w, a) + b)\r\n",
        "    return a"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WyS8_7XrgZc"
      },
      "source": [
        "def evaluate(nn, te_data):\r\n",
        "    test_results = [(np.argmax(forward(nn, x)), y) for (x, y) in te_data]\r\n",
        "    return sum(int(x == y) for (x, y) in test_results)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-_bjK6qrk5M"
      },
      "source": [
        "def evaluate2(nn, te_data):\r\n",
        "    test_results = [(np.argmax(forward(nn, x)), y) for (x, y) in te_data]\r\n",
        "    return sum(int(x == np.argmax(y)) for (x, y) in test_results)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtOCuesNrzW9"
      },
      "source": [
        "def backward(nn, x, y):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    activation = x \r\n",
        "    acts = [x]\r\n",
        "    zs = []     \r\n",
        "\r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        z = np.dot(w, activation) + b \r\n",
        "        zs.append(z)        \r\n",
        "        activation = nn.act(z)   \r\n",
        "        acts.append(activation)\r\n",
        "    delta = dcost(acts[-1], y) * nn.dact(zs[-1])\r\n",
        "    nb[-1] = delta\r\n",
        "    nw[-1] = np.dot(delta, acts[-2].transpose())\r\n",
        "    for i in range(2, nn.num_layers):\r\n",
        "        z = zs[-i]\r\n",
        "        sp = nn.dact(z)\r\n",
        "        delta = np.dot(nn.weights[-i + 1].transpose(), delta) * sp\r\n",
        "        nb[-i] = delta\r\n",
        "        nw[-i] = np.dot(delta, acts[-i - 1].transpose())\r\n",
        "    return (nb, nw)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6qNxD6r1kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c9ec0f-5fb5-463a-8be4-3e71700d290c"
      },
      "source": [
        "import keras\r\n",
        "def change_y(j):\r\n",
        "    e = np.zeros((10, 1))\r\n",
        "    e[j] = 1.0\r\n",
        "    return e\r\n",
        "fashion_mnist = keras.datasets.fashion_mnist\r\n",
        "tr_data, te_data = fashion_mnist.load_data()\r\n",
        "training_x = [np.reshape(x, (784, 1))/255 for x in tr_data[0]]\r\n",
        "training_y = [change_y(y) for y in tr_data[1]]\r\n",
        "tr_data = zip(training_x, training_y)\r\n",
        "test_inputs = [np.reshape(x, (784, 1))/255 for x in te_data[0]]\r\n",
        "te_data = zip(test_inputs, te_data[1])\r\n",
        "tr_data=list(tr_data)\r\n",
        "te_data=list(te_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sICKBOOsMzB",
        "outputId": "a26da5a3-6f62-40f5-80cc-7e3872b00bf1"
      },
      "source": [
        "nn = init_network([784, 30,30, 10],\"sigmoid\")\r\n",
        "epochs = 20\r\n",
        "batch_size =10\r\n",
        "learning_rate = 0.03\r\n",
        "print('start')\r\n",
        "sgdlearn(nn, tr_data, epochs, batch_size, learning_rate)\r\n",
        "print('accuracy {0}%'.format(100.0 * evaluate(nn, te_data) / len(te_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "Epoch  1:time taken 14.4830162525177 seconds, accuracy 72.81333333333333%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}