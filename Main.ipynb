{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcBl0f6W4plxgaUs/QDttA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamCholin/CS6910_Assignment_1/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WMlSMJmqlm-"
      },
      "source": [
        "import random          \r\n",
        "import numpy as np      \r\n",
        "from time import time    "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcofG8yhqqYQ"
      },
      "source": [
        "def sigmoid(z):\r\n",
        "    return 1.0 / (1.0 + np.exp(-z))\r\n",
        "def dsigmoid(z):\r\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_X3V9XArT_m"
      },
      "source": [
        "def relu(z):\r\n",
        "    return np.maximum(z, 0)\r\n",
        "def drelu(z):\r\n",
        "    return np.heaviside(z, 1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYPGfYXsv_I-"
      },
      "source": [
        "def tanh(z):\r\n",
        "    return (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\r\n",
        "def dtanh(z):\r\n",
        "    return 1-tanh(z)**2"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4UwSCkm14dg"
      },
      "source": [
        "def softmax(x):\r\n",
        "\t\te_x = np.exp(x - np.max(x))\r\n",
        "\t\treturn e_x / np.sum(e_x)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MQpaihqL169"
      },
      "source": [
        "def sqdcost_d(act,y,s):\r\n",
        "    act=softmax(act)\r\n",
        "    ret=[]\r\n",
        "    ll=len(act)\r\n",
        "    for j in range(ll):\r\n",
        "      add=0\r\n",
        "      for i in range(ll):\r\n",
        "        add+=2*(act[i]-y[i])*act[i]*((i==j)-act[j])\r\n",
        "      ret.append(add)\r\n",
        "    return np.array(ret)/s"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegcauxLqvIm"
      },
      "source": [
        "def cecost_d(act, y,s):\r\n",
        "    act=softmax(act)\r\n",
        "    act= act-y\r\n",
        "    return act"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtOCuesNrzW9"
      },
      "source": [
        "def backward(nn, x, y):\r\n",
        "    m = x.shape[1]\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    activation = x \r\n",
        "    acts = [x]\r\n",
        "    zs = []    \r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        z = np.dot(w, activation) + b \r\n",
        "        zs.append(z)        \r\n",
        "        activation = nn.act(z)   \r\n",
        "        acts.append(activation)\r\n",
        "    delta = nn.cost(acts[-1], y,nn.batch_size) * nn.dact(zs[-1])\r\n",
        "    nb[-1] = delta\r\n",
        "    nw[-1] = np.dot(delta, acts[-2].transpose()) + nn.lmbda * nn.weights[-1]\r\n",
        "    for i in range(2, nn.num_layers):\r\n",
        "        z = zs[-i]\r\n",
        "        sp = nn.dact(z)\r\n",
        "        delta = np.dot(nn.weights[-i + 1].transpose(), delta) * sp\r\n",
        "        nb[-i] = delta\r\n",
        "        nw[-i] = np.dot(delta, acts[-i - 1].transpose())+ nn.lmbda * nn.weights[-i]\r\n",
        "    return (nb, nw)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFG5UD_ZIr20"
      },
      "source": [
        "def nagbackward(nn, x, y):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    activation = x \r\n",
        "    acts = [x]\r\n",
        "    zs = []  \r\n",
        "    new_weights = [w-v*nn.gamma for w,v in zip(nn.weights,nn.vw)]\r\n",
        "    new_biases = [b-v*nn.gamma for b,v in zip(nn.biases,nn.vb)]\r\n",
        "    for b, w in zip(new_biases, new_weights):\r\n",
        "        z = np.dot(w, activation) + b \r\n",
        "        zs.append(z)        \r\n",
        "        activation = nn.act(z)   \r\n",
        "        acts.append(activation)\r\n",
        "    delta = nn.cost(acts[-1], y,nn.batch_size) * nn.dact(zs[-1])\r\n",
        "    nb[-1] = delta\r\n",
        "    nw[-1] = np.dot(delta, acts[-2].transpose())+ nn.lmbda * nn.weights[-1]\r\n",
        "    for i in range(2, nn.num_layers):\r\n",
        "        z = zs[-i]\r\n",
        "        sp = nn.dact(z)\r\n",
        "        delta = np.dot(new_weights[-i + 1].transpose(), delta) * sp\r\n",
        "        nb[-i] = delta\r\n",
        "        nw[-i] = np.dot(delta, acts[-i - 1].transpose())+ nn.lmbda * nn.weights[-i]\r\n",
        "    return (nb, nw)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBnrQr7ArnSZ"
      },
      "source": [
        "def learn(nn, tr_data):\r\n",
        "    n = len(tr_data)\r\n",
        "    for j in range(nn.epochs):\r\n",
        "        time_start=time()\r\n",
        "        random.shuffle(tr_data)\r\n",
        "        batches = [tr_data[k: k + nn.batch_size] for k in range(0,n,nn.batch_size)]\r\n",
        "        for batch in batches:\r\n",
        "            nn.grad(nn, batch)\r\n",
        "        time_end=time()\r\n",
        "        print('Epoch {0}:time taken {1} seconds, accuracy {2}%'.format(f'{j + 1:2}',1.0*time_end-time_start, 100.0 * evaluate2(nn, tr_data) / len(tr_data)))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hHbAvP5rdA9"
      },
      "source": [
        "def forward(nn, a):\r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        a = nn.act(np.dot(w, a) + b)\r\n",
        "    return a"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMpeRG-YzmXL"
      },
      "source": [
        "def sgd(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    num=1\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y)\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "    nn.weights = [w - (nn.learning_rate ) * nw for w, nw in zip(nn.weights, nw)]\r\n",
        "    nn.biases  = [b - (nn.learning_rate) * nb for b, nb in zip(nn.biases, nb)]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIM4l7Tu9r7-"
      },
      "source": [
        "def mbgd(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.vw = [vweight*nn.gamma + nn.learning_rate * nw for vweight,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [vbiases*nn.gamma + nn.learning_rate * nb for vbiases,nb in zip(nn.vb,nb)]\r\n",
        "    nn.weights = [w - v for w, v in zip(nn.weights, nn.vw)]\r\n",
        "    nn.biases  = [b - v for b, v in zip(nn.biases, nn.vb)]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu_LsbYM-EBX"
      },
      "source": [
        "def nag(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = nagbackward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.vw = [vweight*nn.gamma + nn.learning_rate * nw for vweight,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [vbiases*nn.gamma + nn.learning_rate * nb for vbiases,nb in zip(nn.vb,nb)]\r\n",
        "    nn.weights = [w - v for w, v in zip(nn.weights, nn.vw)]\r\n",
        "    nn.biases  = [b - v for b, v in zip(nn.biases, nn.vb)]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFbvuk4F9rkO"
      },
      "source": [
        "def rmsprop(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.gew = [gew*nn.gamma + (1.0-nn.gamma)*np.square(nw) for gew,nw in zip(nn.gew,nw)]\r\n",
        "    nn.geb = [geb*nn.gamma + (1.0-nn.gamma)*np.square(nb) for geb,nb in zip(nn.geb,nb)]\r\n",
        "    nn.weights = [w - nn.learning_rate * nw / np.sqrt(ge+nn.epsilon) for w, ge,nw in zip(nn.weights, nn.gew,nw)]\r\n",
        "    nn.biases  = [b - nn.learning_rate * nb / np.sqrt(ge+nn.epsilon) for b, ge,nb in zip(nn.biases, nn.geb,nb)]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7v1eR3r-Zv5"
      },
      "source": [
        "def adam(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.mw = [nn.beta1w*m + (1.0-nn.beta1w)*nw for m,nw in zip(nn.mw,nw)]\r\n",
        "    nn.mb = [nn.beta1b*m + (1.0-nn.beta1b)*nb for m,nb in zip(nn.mb,nb)]\r\n",
        "    nn.vw = [nn.beta2w*v + (1.0-nn.beta2w)*np.square(nw) for v,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [nn.beta2b*v + (1.0-nn.beta2b)*np.square(nb) for v,nb in zip(nn.vb,nb)]\r\n",
        "    nn.beta1_expw *= nn.beta1w\r\n",
        "    nn.beta2_expw *= nn.beta2w\r\n",
        "    nn.beta1_expb *= nn.beta1b\r\n",
        "    nn.beta2_expb *= nn.beta2b\r\n",
        "    nn.weights = [w - nn.learning_rate *(m/(1.0-nn.beta1_expw))/ (np.sqrt(v / (1.0 - nn.beta2_expw)) + nn.epsilon) for w, m,v in zip(nn.weights, nn.mw,nn.vw)]\r\n",
        "    nn.biases = [b - nn.learning_rate *(m/(1.0-nn.beta1_expb))/ (np.sqrt(v / (1.0 - nn.beta2_expb)) + nn.epsilon) for b, m,v in zip(nn.biases, nn.mb,nn.vb)]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1soG0ZT9q_m"
      },
      "source": [
        "def nadam(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "\r\n",
        "    nn.mw = [nn.beta1w*m + (1.0-nn.beta1w)*nw for m,nw in zip(nn.mw,nw)]\r\n",
        "    nn.mb = [nn.beta1b*m + (1.0-nn.beta1b)*nb for m,nb in zip(nn.mb,nb)]\r\n",
        "    nn.vw = [nn.beta2w*v + (1.0-nn.beta2w)*np.square(nw) for v,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [nn.beta2b*v + (1.0-nn.beta2b)*np.square(nb) for v,nb in zip(nn.vb,nb)]\r\n",
        "    #nn.weights = [w - (eta ) * nw for w, nw in zip(nn.weights, nw)]\r\n",
        "    #nn.biases  = [b - (eta ) * nb for b, nb in zip(nn.biases, nb)]\r\n",
        "    nn.beta1_expw *= nn.beta1w\r\n",
        "    nn.beta2_expw *= nn.beta2w\r\n",
        "    nn.beta1_expb *= nn.beta1b\r\n",
        "    nn.beta2_expb *= nn.beta2b\r\n",
        "    mwn=[m/(1-nn.beta1_expw) for m in nn.mw]\r\n",
        "    vwn=[v/(1-nn.beta2_expw) for v in nn.vw]\r\n",
        "    mbn=[m/(1-nn.beta1_expb) for m in nn.mb]\r\n",
        "    vbn=[v/(1-nn.beta2_expb) for v in nn.vb]\r\n",
        "    mwnn=[nn.beta1w * m + ((1-nn.beta1w)/(1-nn.beta1_expw))*g for m,g in zip(mwn,nw)]\r\n",
        "    mbnn=[nn.beta1b * m + ((1-nn.beta1b)/(1-nn.beta1_expb))*g for m,g in zip(mbn,nb)]\r\n",
        "\r\n",
        "    nn.weights = [w - nn.learning_rate *m/ (np.sqrt(v) + nn.epsilon) for w, m,v in zip(nn.weights, mwnn,vwn)]\r\n",
        "    nn.biases = [b - nn.learning_rate *m/ (np.sqrt(v)+ nn.epsilon) for b, m,v in zip(nn.biases, mbnn,vbn)]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO4oZbwlqyzm"
      },
      "source": [
        "class Network:\r\n",
        "    num_layers=0\r\n",
        "    biases=[]\r\n",
        "    weights=[]\r\n",
        "    def __init__(self,nl,x,y,act1,act2,lmbda,g_func,c_func,lr,bs,e):\r\n",
        "      self.num_layers=nl\r\n",
        "      self.biases=x\r\n",
        "      self.weights=y\r\n",
        "      self.act=act1\r\n",
        "      self.dact=act2\r\n",
        "      self.grad=g_func\r\n",
        "      self.vw=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.vb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.mw=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.mb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.gew=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.geb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.gamma=0.9\r\n",
        "      self.epsilon = 1e-8\r\n",
        "      self.beta1w = 0.9\r\n",
        "      self.beta2w = 0.999\r\n",
        "      self.beta1_expw = 1.0\r\n",
        "      self.beta2_expw = 1.0\r\n",
        "      self.beta1b = 0.9\r\n",
        "      self.beta2b = 0.999\r\n",
        "      self.beta1_expb = 1.0\r\n",
        "      self.beta2_expb = 1.0\r\n",
        "      self.lmbda=lmbda\r\n",
        "      self.cost=c_func\r\n",
        "      self.learning_rate=lr\r\n",
        "      self.epochs=e\r\n",
        "      self.batch_size=bs\r\n",
        "\r\n",
        "def init_network(layers,actfunc,lmbda,grad_function,Loss_f,lr,bs,e):\r\n",
        "    if actfunc==\"tanh\":\r\n",
        "      act1=tanh\r\n",
        "      act2=dtanh\r\n",
        "    elif actfunc==\"sigmoid\":\r\n",
        "      act1=sigmoid\r\n",
        "      act2=dsigmoid\r\n",
        "    else:\r\n",
        "      act1=relu\r\n",
        "      act2=drelu\r\n",
        "    if grad_function==\"SGD\":\r\n",
        "      g_func=sgd\r\n",
        "    elif grad_function==\"MBGD\":\r\n",
        "      g_func=mbgd\r\n",
        "    elif grad_function==\"NAG\":\r\n",
        "      g_func=nag\r\n",
        "    elif grad_function==\"RMSPROP\":\r\n",
        "      g_func=rmsprop\r\n",
        "    elif grad_function==\"ADAM\":\r\n",
        "      g_func=adam\r\n",
        "    elif grad_function==\"NADAM\":\r\n",
        "      g_func=nadam\r\n",
        "    if Loss_f==\"MSE\":\r\n",
        "      cost_func=sqdcost_d\r\n",
        "    else:\r\n",
        "      cost_func=cecost_d\r\n",
        "    return Network(len(layers),[np.random.randn(y, 1) for y in layers[1:]],[np.random.randn(y, x) for x, y in zip(layers[:-1], layers[1:])],act1,act2,lmbda,g_func,cost_func,lr,bs,e)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WyS8_7XrgZc"
      },
      "source": [
        "def evaluate(nn, te_data):\r\n",
        "    test_results = [(np.argmax(forward(nn, x)), y) for (x, y) in te_data]\r\n",
        "    return sum(int(x == y) for (x, y) in test_results)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-_bjK6qrk5M"
      },
      "source": [
        "def evaluate2(nn, te_data):\r\n",
        "    test_results = [(np.argmax(forward(nn, x)), y) for (x, y) in te_data]\r\n",
        "    return sum(int(x == np.argmax(y)) for (x, y) in test_results)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6qNxD6r1kz"
      },
      "source": [
        "import keras\r\n",
        "def change_y(j):\r\n",
        "    e = np.zeros((10, 1))\r\n",
        "    e[j] = 1.0\r\n",
        "    return e\r\n",
        "fashion_mnist = keras.datasets.fashion_mnist\r\n",
        "tr_data, te_data = fashion_mnist.load_data()\r\n",
        "training_x = [np.reshape(x, (784, 1))/255 for x in tr_data[0]]\r\n",
        "training_y = [change_y(y) for y in tr_data[1]]\r\n",
        "tr_data = zip(training_x, training_y)\r\n",
        "test_inputs = [np.reshape(x, (784, 1))/255 for x in te_data[0]]\r\n",
        "te_data = zip(test_inputs, te_data[1])\r\n",
        "tr_data=list(tr_data)\r\n",
        "te_data=list(te_data)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sICKBOOsMzB",
        "outputId": "4ad142b9-854a-4b20-ae03-88fa3a046590"
      },
      "source": [
        "no_of_hlayers=2\r\n",
        "size_of_each_hlayer=32\r\n",
        "# Activation functions can be \"sigmoid\" , \"tanh\" and \"Relu\"\r\n",
        "Activation_function=\"sigmoid\"\r\n",
        "L2_regularisation=0\r\n",
        "#optimization functions can be \"SGD\" , \"MBGD\" , \"NAG\" , \"RMSPROP\" , \"ADAM\", \"NADAM\"\r\n",
        "Gradient_descent_optimizer=\"SGD\"\r\n",
        "epochs = 10\r\n",
        "batch_size =10\r\n",
        "learning_rate = 0.3\r\n",
        "# loss to optimize , can be \"Cross_entropy\" or \"MSE\"\r\n",
        "loss_function = \"Cross_entropy\"\r\n",
        "L=[]\r\n",
        "L.append(784)\r\n",
        "for _ in range(no_of_hlayers):\r\n",
        "  L.append(size_of_each_hlayer)\r\n",
        "L.append(10)\r\n",
        "nn = init_network(L,Activation_function,L2_regularisation,Gradient_descent_optimizer,loss_function,learning_rate,batch_size,epochs)\r\n",
        "print('start')\r\n",
        "learn(nn, tr_data)\r\n",
        "print('accuracy {0}%'.format(100.0 * evaluate(nn, te_data) / len(te_data)))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "Epoch  1:time taken 21.90295958518982 seconds, accuracy 72.11166666666666%\n",
            "Epoch  2:time taken 21.917940139770508 seconds, accuracy 72.59833333333333%\n",
            "Epoch  3:time taken 22.307148933410645 seconds, accuracy 76.59%\n",
            "Epoch  4:time taken 21.885160207748413 seconds, accuracy 76.47833333333334%\n",
            "Epoch  5:time taken 22.096740245819092 seconds, accuracy 78.14666666666666%\n",
            "Epoch  6:time taken 21.90775442123413 seconds, accuracy 75.72666666666667%\n",
            "Epoch  7:time taken 21.84419083595276 seconds, accuracy 75.34333333333333%\n",
            "Epoch  8:time taken 21.879703044891357 seconds, accuracy 73.76333333333334%\n",
            "Epoch  9:time taken 21.81201958656311 seconds, accuracy 78.73333333333333%\n",
            "Epoch 10:time taken 21.980120420455933 seconds, accuracy 78.78333333333333%\n",
            "accuracy 77.16%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}