{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzZHnzFpKO+O8ZDeA+NL6W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamCholin/FeedForward_NeuralNetwork/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WMlSMJmqlm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1331a2f-cbce-4705-b326-89c8f2b380ca"
      },
      "source": [
        "import random          \r\n",
        "import numpy as np      \r\n",
        "from time import time    \r\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ae/79374d2b875e638090600eaa2a423479865b7590c53fb78e8ccf6a64acb1/wandb-0.10.22-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 19.9MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 17.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=105109c8cc41bad0e879e6216969a5cf95c9944dd4f980b873049fcc399a51e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=09902837b552f9c752d93bd10ddfccda183221cec2eb2f2b3c659366a2c316a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: configparser, pathtools, shortuuid, subprocess32, docker-pycreds, smmap, gitdb, GitPython, sentry-sdk, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcofG8yhqqYQ"
      },
      "source": [
        "def sigmoid(z):\r\n",
        "    return 1.0 / (1.0 + np.exp(-z))\r\n",
        "def dsigmoid(z):\r\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_X3V9XArT_m"
      },
      "source": [
        "def relu(z):\r\n",
        "    return np.maximum(z, 0)\r\n",
        "def drelu(z):\r\n",
        "    return np.heaviside(z, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYPGfYXsv_I-"
      },
      "source": [
        "def tanh(z):\r\n",
        "    return np.tanh(z)\r\n",
        "def dtanh(z):\r\n",
        "    return 1-tanh(z)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4UwSCkm14dg"
      },
      "source": [
        "def softmax(x):\r\n",
        "\t\te_x = np.exp(x)\r\n",
        "\t\treturn e_x / np.sum(e_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJNK-1EVfD95"
      },
      "source": [
        "def sqd_loss(nn, te_data):\r\n",
        "  loss=0\r\n",
        "  for x,y in te_data:\r\n",
        "    act=forward(nn,x)\r\n",
        "    act=softmax(act)\r\n",
        "    loss+=np.sum((act-y)**2)\r\n",
        "  return loss/len(te_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQjHS4Tvgi7z"
      },
      "source": [
        "def ce_loss(nn, te_data):\r\n",
        "  loss=0\r\n",
        "  for x,y in te_data:\r\n",
        "    act=forward(nn,x)\r\n",
        "    act=softmax(act)\r\n",
        "    loss+=(-np.log(max(act))+(nn.lmbda/2)*np.sum([np.sum(w**2) for w in nn.weights]))[0]\r\n",
        "  return loss/len(te_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MQpaihqL169"
      },
      "source": [
        "def sqdcost_d(act,y,s):\r\n",
        "    act=softmax(act)\r\n",
        "    ret=[]\r\n",
        "    ll=len(act)\r\n",
        "    for j in range(ll):\r\n",
        "      add=0\r\n",
        "      for i in range(ll):\r\n",
        "        add+=2*(act[i]-y[i])*act[i]*((i==j)-act[j])\r\n",
        "      ret.append(add)\r\n",
        "    return np.array(ret)/s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegcauxLqvIm"
      },
      "source": [
        "def cecost_d(act, y,s):\r\n",
        "    act=softmax(act)\r\n",
        "    act= act-y\r\n",
        "    return act"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtOCuesNrzW9"
      },
      "source": [
        "def backward(nn, x, y):\r\n",
        "    m = x.shape[1]\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    activation = x \r\n",
        "    acts = [x]\r\n",
        "    zs = []    \r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        z = np.dot(w, activation) + b \r\n",
        "        zs.append(z)        \r\n",
        "        activation = nn.act(z)   \r\n",
        "        acts.append(activation)\r\n",
        "    delta = nn.cost(acts[-1], y,nn.batch_size) * nn.dact(zs[-1])\r\n",
        "    nb[-1] = delta\r\n",
        "    nw[-1] = np.dot(delta, acts[-2].transpose()) + nn.lmbda * nn.weights[-1]\r\n",
        "    for i in range(2, nn.num_layers):\r\n",
        "        z = zs[-i]\r\n",
        "        sp = nn.dact(z)\r\n",
        "        delta = np.dot(nn.weights[-i + 1].transpose(), delta) * sp\r\n",
        "        nb[-i] = delta\r\n",
        "        nw[-i] = np.dot(delta, acts[-i - 1].transpose())+ nn.lmbda * nn.weights[-i]\r\n",
        "    return (nb, nw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFG5UD_ZIr20"
      },
      "source": [
        "def nagbackward(nn, x, y):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    activation = x \r\n",
        "    acts = [x]\r\n",
        "    zs = []  \r\n",
        "    new_weights = [w-v*nn.gamma for w,v in zip(nn.weights,nn.vw)]\r\n",
        "    new_biases = [b-v*nn.gamma for b,v in zip(nn.biases,nn.vb)]\r\n",
        "    for b, w in zip(new_biases, new_weights):\r\n",
        "        z = np.dot(w, activation) + b \r\n",
        "        zs.append(z)        \r\n",
        "        activation = nn.act(z)   \r\n",
        "        acts.append(activation)\r\n",
        "    delta = nn.cost(acts[-1], y,nn.batch_size) * nn.dact(zs[-1])\r\n",
        "    nb[-1] = delta\r\n",
        "    nw[-1] = np.dot(delta, acts[-2].transpose())+ nn.lmbda * nn.weights[-1]\r\n",
        "    for i in range(2, nn.num_layers):\r\n",
        "        z = zs[-i]\r\n",
        "        sp = nn.dact(z)\r\n",
        "        delta = np.dot(new_weights[-i + 1].transpose(), delta) * sp\r\n",
        "        nb[-i] = delta\r\n",
        "        nw[-i] = np.dot(delta, acts[-i - 1].transpose())+ nn.lmbda * nn.weights[-i]\r\n",
        "    return (nb, nw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBnrQr7ArnSZ"
      },
      "source": [
        "def learn(nn, tr_data,te_data,va_data):\r\n",
        "    n = len(tr_data)\r\n",
        "    for j in range(nn.epochs):\r\n",
        "        time_start=time()\r\n",
        "        random.shuffle(tr_data)\r\n",
        "        batches = [tr_data[k: k + nn.batch_size] for k in range(0,n,nn.batch_size)]\r\n",
        "        for batch in batches:\r\n",
        "            nn.grad(nn, batch)\r\n",
        "        time_end=time()\r\n",
        "        print('Epoch {0}:time taken {1} seconds, accuracy {2} % , loss {3}'.format(f'{j + 1:2}',1.0*time_end-time_start, 100.0 * evaluate(nn, tr_data) / len(tr_data), nn.loss(nn,tr_data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hHbAvP5rdA9"
      },
      "source": [
        "def forward(nn, a):\r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        a = nn.act(np.dot(w, a) + b)\r\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMpeRG-YzmXL"
      },
      "source": [
        "def sgd(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    num=1\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y)\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "    nn.weights = [w - (nn.learning_rate ) * nw for w, nw in zip(nn.weights, nw)]\r\n",
        "    nn.biases  = [b - (nn.learning_rate) * nb for b, nb in zip(nn.biases, nb)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIM4l7Tu9r7-"
      },
      "source": [
        "def mbgd(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.vw = [vweight*nn.gamma + nn.learning_rate * nw for vweight,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [vbiases*nn.gamma + nn.learning_rate * nb for vbiases,nb in zip(nn.vb,nb)]\r\n",
        "    nn.weights = [w - v for w, v in zip(nn.weights, nn.vw)]\r\n",
        "    nn.biases  = [b - v for b, v in zip(nn.biases, nn.vb)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu_LsbYM-EBX"
      },
      "source": [
        "def nag(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = nagbackward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.vw = [vweight*nn.gamma + nn.learning_rate * nw for vweight,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [vbiases*nn.gamma + nn.learning_rate * nb for vbiases,nb in zip(nn.vb,nb)]\r\n",
        "    nn.weights = [w - v for w, v in zip(nn.weights, nn.vw)]\r\n",
        "    nn.biases  = [b - v for b, v in zip(nn.biases, nn.vb)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFbvuk4F9rkO"
      },
      "source": [
        "def rmsprop(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.gew = [gew*nn.gamma + (1.0-nn.gamma)*np.square(nw) for gew,nw in zip(nn.gew,nw)]\r\n",
        "    nn.geb = [geb*nn.gamma + (1.0-nn.gamma)*np.square(nb) for geb,nb in zip(nn.geb,nb)]\r\n",
        "    nn.weights = [w - nn.learning_rate * nw / np.sqrt(ge+nn.epsilon) for w, ge,nw in zip(nn.weights, nn.gew,nw)]\r\n",
        "    nn.biases  = [b - nn.learning_rate * nb / np.sqrt(ge+nn.epsilon) for b, ge,nb in zip(nn.biases, nn.geb,nb)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7v1eR3r-Zv5"
      },
      "source": [
        "def adam(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "    nn.mw = [nn.beta1w*m + (1.0-nn.beta1w)*nw for m,nw in zip(nn.mw,nw)]\r\n",
        "    nn.mb = [nn.beta1b*m + (1.0-nn.beta1b)*nb for m,nb in zip(nn.mb,nb)]\r\n",
        "    nn.vw = [nn.beta2w*v + (1.0-nn.beta2w)*np.square(nw) for v,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [nn.beta2b*v + (1.0-nn.beta2b)*np.square(nb) for v,nb in zip(nn.vb,nb)]\r\n",
        "    nn.beta1_expw *= nn.beta1w\r\n",
        "    nn.beta2_expw *= nn.beta2w\r\n",
        "    nn.beta1_expb *= nn.beta1b\r\n",
        "    nn.beta2_expb *= nn.beta2b\r\n",
        "    nn.weights = [w - nn.learning_rate *(m/(1.0-nn.beta1_expw))/ (np.sqrt(v / (1.0 - nn.beta2_expw)) + nn.epsilon) for w, m,v in zip(nn.weights, nn.mw,nn.vw)]\r\n",
        "    nn.biases = [b - nn.learning_rate *(m/(1.0-nn.beta1_expb))/ (np.sqrt(v / (1.0 - nn.beta2_expb)) + nn.epsilon) for b, m,v in zip(nn.biases, nn.mb,nn.vb)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1soG0ZT9q_m"
      },
      "source": [
        "def nadam(nn, batch):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "\r\n",
        "    nn.mw = [nn.beta1w*m + (1.0-nn.beta1w)*nw for m,nw in zip(nn.mw,nw)]\r\n",
        "    nn.mb = [nn.beta1b*m + (1.0-nn.beta1b)*nb for m,nb in zip(nn.mb,nb)]\r\n",
        "    nn.vw = [nn.beta2w*v + (1.0-nn.beta2w)*np.square(nw) for v,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [nn.beta2b*v + (1.0-nn.beta2b)*np.square(nb) for v,nb in zip(nn.vb,nb)]\r\n",
        "    #nn.weights = [w - (eta ) * nw for w, nw in zip(nn.weights, nw)]\r\n",
        "    #nn.biases  = [b - (eta ) * nb for b, nb in zip(nn.biases, nb)]\r\n",
        "    nn.beta1_expw *= nn.beta1w\r\n",
        "    nn.beta2_expw *= nn.beta2w\r\n",
        "    nn.beta1_expb *= nn.beta1b\r\n",
        "    nn.beta2_expb *= nn.beta2b\r\n",
        "    mwn=[m/(1-nn.beta1_expw) for m in nn.mw]\r\n",
        "    vwn=[v/(1-nn.beta2_expw) for v in nn.vw]\r\n",
        "    mbn=[m/(1-nn.beta1_expb) for m in nn.mb]\r\n",
        "    vbn=[v/(1-nn.beta2_expb) for v in nn.vb]\r\n",
        "    mwnn=[nn.beta1w * m + ((1-nn.beta1w)/(1-nn.beta1_expw))*g for m,g in zip(mwn,nw)]\r\n",
        "    mbnn=[nn.beta1b * m + ((1-nn.beta1b)/(1-nn.beta1_expb))*g for m,g in zip(mbn,nb)]\r\n",
        "\r\n",
        "    nn.weights = [w - nn.learning_rate *m/ (np.sqrt(v) + nn.epsilon) for w, m,v in zip(nn.weights, mwnn,vwn)]\r\n",
        "    nn.biases = [b - nn.learning_rate *m/ (np.sqrt(v)+ nn.epsilon) for b, m,v in zip(nn.biases, mbnn,vbn)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO4oZbwlqyzm"
      },
      "source": [
        "class Network:\r\n",
        "    num_layers=0\r\n",
        "    biases=[]\r\n",
        "    weights=[]\r\n",
        "    def __init__(self,nl,x,y,act1,act2,lmbda,g_func,c_func,l_func,lr,bs,e):\r\n",
        "      self.num_layers=nl\r\n",
        "      self.biases=x\r\n",
        "      self.weights=y\r\n",
        "      self.act=act1\r\n",
        "      self.dact=act2\r\n",
        "      self.grad=g_func\r\n",
        "      self.vw=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.vb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.mw=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.mb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.gew=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.geb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.gamma=0.9\r\n",
        "      self.epsilon = 1e-8\r\n",
        "      self.beta1w = 0.9\r\n",
        "      self.beta2w = 0.999\r\n",
        "      self.beta1_expw = 1.0\r\n",
        "      self.beta2_expw = 1.0\r\n",
        "      self.beta1b = 0.9\r\n",
        "      self.beta2b = 0.999\r\n",
        "      self.beta1_expb = 1.0\r\n",
        "      self.beta2_expb = 1.0\r\n",
        "      self.lmbda=lmbda\r\n",
        "      self.cost=c_func\r\n",
        "      self.learning_rate=lr\r\n",
        "      self.epochs=e\r\n",
        "      self.batch_size=bs\r\n",
        "      self.loss=l_func\r\n",
        "\r\n",
        "def init_network(layers,actfunc,lmbda,grad_function,Loss_f,lr,bs,e,xav):\r\n",
        "    if xav:\r\n",
        "      weights=[np.random.randn(y, x)*math.sqrt(6/(x+y)) for x, y in zip(layers[:-1], layers[1:])]\r\n",
        "    else:\r\n",
        "      weights=[np.random.randn(y, x) for x, y in zip(layers[:-1], layers[1:])]\r\n",
        "    biases = [np.random.randn(y, 1) for y in layers[1:]]\r\n",
        "    if actfunc==\"tanh\":\r\n",
        "      act1=tanh\r\n",
        "      act2=dtanh\r\n",
        "    elif actfunc==\"sigmoid\":\r\n",
        "      act1=sigmoid\r\n",
        "      act2=dsigmoid\r\n",
        "    else:\r\n",
        "      act1=relu\r\n",
        "      act2=drelu\r\n",
        "    if grad_function==\"SGD\":\r\n",
        "      g_func=sgd\r\n",
        "    elif grad_function==\"MBGD\":\r\n",
        "      g_func=mbgd\r\n",
        "    elif grad_function==\"NAG\":\r\n",
        "      g_func=nag\r\n",
        "    elif grad_function==\"RMSPROP\":\r\n",
        "      g_func=rmsprop\r\n",
        "    elif grad_function==\"ADAM\":\r\n",
        "      g_func=adam\r\n",
        "    elif grad_function==\"NADAM\":\r\n",
        "      g_func=nadam\r\n",
        "    if Loss_f==\"MSE\":\r\n",
        "      cost_func=sqdcost_d\r\n",
        "      loss_func=sqd_loss\r\n",
        "    else:\r\n",
        "      cost_func=cecost_d\r\n",
        "      loss_func=ce_loss\r\n",
        "    return Network(len(layers),biases,weights,act1,act2,lmbda,g_func,cost_func,loss_func,lr,bs,e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-_bjK6qrk5M"
      },
      "source": [
        "def evaluate(nn, te_data):\r\n",
        "    test_results = [(np.argmax(forward(nn, x)), y) for (x, y) in te_data]\r\n",
        "    return sum(int(x == np.argmax(y)) for (x, y) in test_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6qNxD6r1kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90e6c57-8c02-41ea-dafc-3c1328c7d403"
      },
      "source": [
        "import keras\r\n",
        "def change_y(j):\r\n",
        "    e = np.zeros((10, 1))\r\n",
        "    e[j] = 1.0\r\n",
        "    return e\r\n",
        "fashion_mnist = keras.datasets.fashion_mnist\r\n",
        "tr_data, te_data = fashion_mnist.load_data()\r\n",
        "training_x = [np.reshape(x, (784, 1))/255 for x in tr_data[0]]\r\n",
        "training_y = [change_y(y) for y in tr_data[1]]\r\n",
        "tr_data = zip(training_x, training_y)\r\n",
        "test_inputs = [np.reshape(x, (784, 1))/255 for x in te_data[0]]\r\n",
        "test_y = [change_y(y) for y in te_data[1]]\r\n",
        "te_data = zip(test_inputs, test_y)\r\n",
        "tr_data=list(tr_data)\r\n",
        "va_data=tr_data[0:10000]\r\n",
        "tr_data=tr_data[10000:len(tr_data)]\r\n",
        "te_data=list(te_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sICKBOOsMzB"
      },
      "source": [
        "\r\n",
        "no_of_hlayers=2\r\n",
        "size_of_each_hlayer=30\r\n",
        "Activation_function=\"sigmoid\"\r\n",
        "L2_regularisation=0.0005\r\n",
        "Gradient_descent_optimizer=\"NADAM\"\r\n",
        "epochs = 15\r\n",
        "batch_size =32\r\n",
        "learning_rate = 0.001\r\n",
        "Xavier=1\r\n",
        "loss_function = \"Cross_entropy\"\r\n",
        "L=[]\r\n",
        "L.append(784)\r\n",
        "for _ in range(no_of_hlayers):\r\n",
        "  L.append(size_of_each_hlayer)\r\n",
        "L.append(10)\r\n",
        "nn = init_network(L,Activation_function,L2_regularisation,Gradient_descent_optimizer,loss_function,learning_rate,batch_size,epochs,Xavier)\r\n",
        "print('start')\r\n",
        "learn(nn, tr_data,te_data,va_data)\r\n",
        "print('accuracy {0}%'.format(100.0 * evaluate(nn, te_data) / len(te_data)))\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}