{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAdam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEVbN9loWnuL5djdRm+luT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamCholin/CS6910_Assignment_1/blob/main/NAdam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WMlSMJmqlm-"
      },
      "source": [
        "import random          \r\n",
        "import numpy as np      \r\n",
        "from time import time    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcofG8yhqqYQ"
      },
      "source": [
        "def sigmoid(z):\r\n",
        "    return 1.0 / (1.0 + np.exp(-z))\r\n",
        "def dsigmoid(z):\r\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_X3V9XArT_m"
      },
      "source": [
        "def relu(z):\r\n",
        "    return np.maximum(z, 0)\r\n",
        "def drelu(z):\r\n",
        "    return np.heaviside(z, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYPGfYXsv_I-"
      },
      "source": [
        "def tanh(z):\r\n",
        "    return (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\r\n",
        "def dtanh(z):\r\n",
        "    return 1-tanh(z)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLpEhFHDSEV9"
      },
      "source": [
        "def adamlearn(nn, tr_data, epochs, batch_size, learning_rate):\r\n",
        "    n = len(tr_data)\r\n",
        "    for j in range(epochs):\r\n",
        "        time_start=time()\r\n",
        "        random.shuffle(tr_data)\r\n",
        "        batches = [tr_data[k: k + batch_size] for k in range(0,n,batch_size)]\r\n",
        "        for batch in batches:\r\n",
        "            adam(nn, batch, learning_rate)\r\n",
        "        time_end=time()\r\n",
        "        print('Epoch {0}:time taken {1} seconds, accuracy {2}%'.format(f'{j + 1:2}',1.0*time_end-time_start, 100.0 * evaluate2(nn, tr_data) / len(tr_data)))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gY02TiTSGQQ"
      },
      "source": [
        "def adam(nn, batch, eta):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    for x, y in batch:\r\n",
        "        dnb, dnw = backward(nn, x, y) \r\n",
        "\r\n",
        "        nb = [nb + dnb for nb, dnb in zip(nb, dnb)]\r\n",
        "        nw = [nw + dnw for nw, dnw in zip(nw, dnw)]\r\n",
        "\r\n",
        "\r\n",
        "    nn.mw = [nn.beta1w*m + (1.0-nn.beta1w)*nw for m,nw in zip(nn.mw,nw)]\r\n",
        "    nn.mb = [nn.beta1b*m + (1.0-nn.beta1b)*nb for m,nb in zip(nn.mb,nb)]\r\n",
        "    nn.vw = [nn.beta2w*v + (1.0-nn.beta2w)*np.square(nw) for v,nw in zip(nn.vw,nw)]\r\n",
        "    nn.vb = [nn.beta2b*v + (1.0-nn.beta2b)*np.square(nb) for v,nb in zip(nn.vb,nb)]\r\n",
        "    #nn.weights = [w - (eta ) * nw for w, nw in zip(nn.weights, nw)]\r\n",
        "    #nn.biases  = [b - (eta ) * nb for b, nb in zip(nn.biases, nb)]\r\n",
        "    nn.beta1_expw *= nn.beta1w\r\n",
        "    nn.beta2_expw *= nn.beta2w\r\n",
        "    nn.beta1_expb *= nn.beta1b\r\n",
        "    nn.beta2_expb *= nn.beta2b\r\n",
        "    mwn=[m/(1-nn.beta1_expw) for m in nn.mw]\r\n",
        "    vwn=[v/(1-nn.beta2_expw) for v in nn.vw]\r\n",
        "    mbn=[m/(1-nn.beta1_expb) for m in nn.mb]\r\n",
        "    vbn=[v/(1-nn.beta2_expb) for v in nn.vb]\r\n",
        "    mwnn=[nn.beta1w * m + ((1-nn.beta1w)/(1-nn.beta1_expw))*g for m,g in zip(mwn,nw)]\r\n",
        "    mbnn=[nn.beta1b * m + ((1-nn.beta1b)/(1-nn.beta1_expb))*g for m,g in zip(mbn,nb)]\r\n",
        "\r\n",
        "    nn.weights = [w - eta *m/ (np.sqrt(v) + nn.epsilon) for w, m,v in zip(nn.weights, mwnn,vwn)]\r\n",
        "    nn.biases = [b - eta *m/ (np.sqrt(v)+ nn.epsilon) for b, m,v in zip(nn.biases, mbnn,vbn)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DJsHxbggj-m"
      },
      "source": [
        "https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4UwSCkm14dg"
      },
      "source": [
        "def softmax(x):\r\n",
        "\t\te_x = np.exp(x - np.max(x))\r\n",
        "\t\treturn e_x / np.sum(e_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLSHubalL2fz"
      },
      "source": [
        "def dcost(act, y):\r\n",
        "    act=softmax(act)\r\n",
        "    act= act-y\r\n",
        "    return act"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO4oZbwlqyzm"
      },
      "source": [
        "class Network:\r\n",
        "    num_layers=0\r\n",
        "    biases=[]\r\n",
        "    weights=[]\r\n",
        "    def __init__(self,nl,x,y,act1,act2):\r\n",
        "      self.num_layers=nl\r\n",
        "      self.biases=x\r\n",
        "      self.weights=y\r\n",
        "      self.act=act1\r\n",
        "      self.dact=act2\r\n",
        "      self.vw=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.vb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.mw=[np.zeros(w.shape) for w in self.weights]\r\n",
        "      self.mb=[np.zeros(b.shape) for b in self.biases]\r\n",
        "      self.gamma=0.9\r\n",
        "      self.epsilon = 1e-8\r\n",
        "      self.beta1w = 0.9\r\n",
        "      self.beta2w = 0.999\r\n",
        "      self.beta1_expw = 1.0\r\n",
        "      self.beta2_expw = 1.0\r\n",
        "      self.beta1b = 0.9\r\n",
        "      self.beta2b = 0.999\r\n",
        "      self.beta1_expb = 1.0\r\n",
        "      self.beta2_expb = 1.0\r\n",
        "\r\n",
        "def init_network(layers,actfunc):\r\n",
        "    if actfunc==\"tanh\":\r\n",
        "      act1=tanh\r\n",
        "      act2=dtanh\r\n",
        "    elif actfunc==\"sigmoid\":\r\n",
        "      act1=sigmoid\r\n",
        "      act2=dsigmoid\r\n",
        "    else:\r\n",
        "      act1=relu\r\n",
        "      act2=drelu\r\n",
        "    return Network(len(layers),[np.random.randn(y, 1) for y in layers[1:]],[np.random.randn(y, x) for x, y in zip(layers[:-1], layers[1:])],act1,act2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hHbAvP5rdA9"
      },
      "source": [
        "def forward(nn, a):\r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        a = nn.act(np.dot(w, a) + b)\r\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WyS8_7XrgZc"
      },
      "source": [
        "def evaluate(nn, te_data):\r\n",
        "    test_results = [(np.argmax(forward(nn, x)), y) for (x, y) in te_data]\r\n",
        "    return sum(int(x == y) for (x, y) in test_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-_bjK6qrk5M"
      },
      "source": [
        "def evaluate2(nn, te_data):\r\n",
        "    test_results = [(np.argmax(forward(nn, x)), y) for (x, y) in te_data]\r\n",
        "    return sum(int(x == np.argmax(y)) for (x, y) in test_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtOCuesNrzW9"
      },
      "source": [
        "def backward(nn, x, y):\r\n",
        "    nb = [np.zeros(b.shape) for b in nn.biases]\r\n",
        "    nw = [np.zeros(w.shape) for w in nn.weights]\r\n",
        "    activation = x \r\n",
        "    acts = [x]\r\n",
        "    zs = []\r\n",
        "    for b, w in zip(nn.biases, nn.weights):\r\n",
        "        z = np.dot(w, activation) + b\r\n",
        "        zs.append(z)\r\n",
        "        activation = nn.act(z)\r\n",
        "        acts.append(activation)\r\n",
        "    delta = dcost(acts[-1], y) * nn.dact(zs[-1])\r\n",
        "    nb[-1] = delta\r\n",
        "    nw[-1] = np.dot(delta, acts[-2].transpose())\r\n",
        "    for i in range(2, nn.num_layers):\r\n",
        "        z = zs[-i]\r\n",
        "        sp = nn.dact(z)\r\n",
        "        delta = np.dot(nn.weights[-i + 1].transpose(), delta) * sp\r\n",
        "        nb[-i] = delta\r\n",
        "        nw[-i] = np.dot(delta, acts[-i - 1].transpose())\r\n",
        "    return (nb, nw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6qNxD6r1kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86ee6f9-f551-4eab-fe94-e52a812f90e8"
      },
      "source": [
        "import keras\r\n",
        "def change_y(j):\r\n",
        "    e = np.zeros((10, 1))\r\n",
        "    e[j] = 1.0\r\n",
        "    return e\r\n",
        "fashion_mnist = keras.datasets.fashion_mnist\r\n",
        "tr_data, te_data = fashion_mnist.load_data()\r\n",
        "training_x = [np.reshape(x, (784, 1))/255 for x in tr_data[0]]\r\n",
        "training_y = [change_y(y) for y in tr_data[1]]\r\n",
        "tr_data = zip(training_x, training_y)\r\n",
        "test_inputs = [np.reshape(x, (784, 1))/255 for x in te_data[0]]\r\n",
        "te_data = zip(test_inputs, te_data[1])\r\n",
        "tr_data=list(tr_data)\r\n",
        "te_data=list(te_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sICKBOOsMzB",
        "outputId": "e85c1e58-17f4-461a-f28e-921d1f37afba"
      },
      "source": [
        "nn = init_network([784, 30, 10],\"sigmoid\")\r\n",
        "epochs = 20\r\n",
        "batch_size =10\r\n",
        "learning_rate = 0.001\r\n",
        "print('start')\r\n",
        "adamlearn(nn, tr_data, epochs, batch_size, learning_rate)\r\n",
        "print('accuracy {0}%'.format(100.0 * evaluate(nn, te_data) / len(te_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "Epoch  1:time taken 13.932281732559204 seconds, accuracy 74.14166666666667%\n",
            "Epoch  2:time taken 14.014456033706665 seconds, accuracy 76.85166666666667%\n",
            "Epoch  3:time taken 14.686495780944824 seconds, accuracy 83.60833333333333%\n",
            "Epoch  4:time taken 14.51518702507019 seconds, accuracy 84.75666666666666%\n",
            "Epoch  5:time taken 14.139208316802979 seconds, accuracy 85.47166666666666%\n",
            "Epoch  6:time taken 13.327604532241821 seconds, accuracy 86.27%\n",
            "Epoch  7:time taken 14.089190006256104 seconds, accuracy 86.49833333333333%\n",
            "Epoch  8:time taken 14.808167457580566 seconds, accuracy 86.97166666666666%\n",
            "Epoch  9:time taken 13.78586220741272 seconds, accuracy 87.22166666666666%\n",
            "Epoch 10:time taken 14.244349479675293 seconds, accuracy 87.52166666666666%\n",
            "Epoch 11:time taken 13.508366584777832 seconds, accuracy 87.71833333333333%\n",
            "Epoch 12:time taken 14.109006404876709 seconds, accuracy 87.95166666666667%\n",
            "Epoch 13:time taken 13.750356912612915 seconds, accuracy 88.35666666666667%\n",
            "Epoch 14:time taken 13.549616575241089 seconds, accuracy 88.395%\n",
            "Epoch 15:time taken 13.87145209312439 seconds, accuracy 88.68833333333333%\n",
            "Epoch 16:time taken 14.250003814697266 seconds, accuracy 88.78666666666666%\n",
            "Epoch 17:time taken 13.37365198135376 seconds, accuracy 88.99%\n",
            "Epoch 18:time taken 14.259069919586182 seconds, accuracy 89.05%\n",
            "Epoch 19:time taken 13.735528230667114 seconds, accuracy 89.32166666666667%\n",
            "Epoch 20:time taken 13.175664901733398 seconds, accuracy 89.49166666666666%\n",
            "accuracy 86.15%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}